{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import csv\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT MODELS AND DICTIONARIES (THIS FILES MUST BE CREATED)\n",
    "\n",
    "reader = csv.reader(open('../../AGAIN/dictionaries/dict_id_ntitle_final.csv', 'r', encoding='utf-8'))\n",
    "dict_id_ntitle = {k:v for (k,v) in reader}\n",
    "reader = csv.reader(open('../../AGAIN/dictionaries/dict_id_ntitle_final.csv', 'r', encoding='utf-8'))\n",
    "dict_ntitle_id = {v:k for (k,v) in reader}\n",
    "reader = csv.reader(open('dictionaries/dict_sorted_trackuri_id.csv', 'r')) #track_uri --- ID : csv to dict\n",
    "dict_trackuri_id = {k:v for (k,v) in reader}\n",
    "reader = csv.reader(open('dictionaries/dict_sorted_trackuri_id.csv', 'r')) #track_uri --- ID : csv to dict\n",
    "dict_id_trackuri = {v:k for (k,v) in reader} \n",
    "\n",
    "# MODEL TRACKS \n",
    "## TRAIN A TRACK MODEL using 4_word2vec_tracks.ipynb or \n",
    "# download all files from the following link: \n",
    "# https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/Ea6m1MuwP_5KjN3ObPU1_x8BODAfx5R8sSz6xggHV3KBDw?e=NmhK9i\n",
    "# https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/ESxbQt1B0NRGsDfyO7D7xsYBYoDVX0STFyxqBlUHwyR4Pg?e=d3HVoC\n",
    "# https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/ES-LksqUbH5FoMNxf22OZs4BqmaLALdb0p0FT2tZYObfsQ?e=5FI1Io\n",
    "model_track = Word2Vec.load(\"models/wv_model_mincount5_shuffle_size300_MPD\")\n",
    "# TRAIN a TITLE MODEL using 5_word2vec_titles.ipynb or\n",
    "# download all files from the following link: \n",
    "# https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/EfGlzz7D3wpHmeNlBXTJ4C8BNYHz-na2PdpdHZ0lBzpDeA?e=xUNBqg\n",
    "model_ntitle = Word2Vec.load(\"models/wv_model_titles_MPD_final\")\n",
    "# TRAIN a ARTIST MODEL using 6_word2vec_artist.ipynb or\n",
    "# download all files from the following link: \n",
    "# https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/EZ3dZt-_5GpJop2KffBm-LsBlr3tUrnQq-5_OkEYYOBx2g?e=2iXZiC\n",
    "# https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/Ebr4qcKcsI9PoEX7xA_AAmkB_d_e5ixYaUi2lSZnYhAR3w?e=b4Bn4Q\n",
    "# https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/EdxvFoNmXA9DlxYrQF3MXugBg-2yfcJim2zt5LvgfrLenQ?e=7gZIDG\n",
    "model_artist = Word2Vec.load(\"models/wv_model_artists_unique_size_100_MPD\")\n",
    "\n",
    "# UNCERTAINTY TITLES MODEL \n",
    "#model_ntitle_uncert = KeyedVectors.load(\"../models/uncertainty/wv_model_certain_titles_MPD_final\")\n",
    "# TRAIN a ARTIST MODEL using 7_uncertainty_model.ipynb or\n",
    "# download it from here: https://ubarcelona-my.sharepoint.com/:u:/g/personal/santi_segui_ub_edu/EVP6RI6PAsdHu9Cu-xezc5MB7-_rNJGEX-y_ZJpnT09eXQ?e=VWBTgl\n",
    "sigmas = pickle.load( open( \"models/sigmas.p\", \"rb\" ) )\n",
    "\n",
    "# most common 1000 tracks per title\n",
    "title_tracks = np.load('../../AGAIN/dictionaries/ntitles_1000tracks_final.npy').tolist()\n",
    "artist_tracks = np.load('../../AGAIN/dictionaries/nartists_1000tracks_final.npy').tolist()\n",
    "\n",
    "\n",
    "reader = csv.reader(open('../../AGAIN/dictionaries/dict_artisturi_id.csv', 'r')) #track_uri --- ID : csv to dict\n",
    "dict_artisturi_id = {k:v for (k,v) in reader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## RECOMMENDATION BY TITLE ARTIST (TITLE == ARTIST)\n",
    "def playlist_recommend_by_title_artist(playlist):\n",
    "    weight_method = 1.0\n",
    "    add_rec_artist = False\n",
    "    if normalize_name(playlist[\"name\"]) not in nop_titles and  normalize_name(playlist[\"name\"]) in artist_tracks.keys():\n",
    "        #check if artist is in the top 6.000 artists\n",
    "        # Why 6.000? lets change it to 20.000\n",
    "        if normalize_name(playlist[\"name\"]) in list(artist_tracks.keys())[:6000]:\n",
    "            tit = normalize_name(playlist[\"name\"])\n",
    "            #GET list of artist' songs\n",
    "            rec_artist = [dict_trackuri_id[t[0]] for t in artist_tracks[tit] if t[0] in dict_trackuri_id ]\n",
    "            if('tracks' in playlist):\n",
    "                if(len(playlist['tracks'])==0):\n",
    "                    add_rec_artist = True\n",
    "                else:\n",
    "                    artist_list = [item['artist_name'] for item in playlist['tracks']]\n",
    "                    normalized_artist_list = [normalize_name(item) for item in artist_list]\n",
    "                    if((len(set(artist_list))-1)/float(len(artist_list))<=0.2):\n",
    "                        if(tit in normalized_artist_list):\n",
    "                            add_rec_artist = True\n",
    "\n",
    "    if(add_rec_artist):\n",
    "        return rec_artist\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RECOMMENDATION BY TITLE\n",
    "def playlist_recommend_by_title(playlist, title_tracks,params):\n",
    "    title_recommendations = []\n",
    "    tit = normalize_name(playlist[\"name\"])   \n",
    "        \n",
    "    if tit not in dict_ntitle_id.keys():\n",
    "        tit = tit.split(\" \")[0]\n",
    "    if tit not in dict_ntitle_id.keys():\n",
    "        tit = tit.lower()\n",
    "        tit = re.sub(r\"[.,'\\/#!$%\\^\\*;:{}=\\_`~()@]\", ' ', tit)\n",
    "        tit = re.sub(r'\\s+', ' ', tit).strip()      \n",
    "\n",
    "     # ARTISTS \n",
    "    '''if \"name\" in playlist:\n",
    "        if normalize_name(playlist[\"name\"]) not in nop_titles and  normalize_name(playlist[\"name\"]) in artist_tracks.keys():\n",
    "            if normalize_name(playlist[\"name\"]) in list(artist_tracks.keys())[:6000]:\n",
    "                tit = normalize_name(playlist[\"name\"])\n",
    "                recommendations[playlist[\"pid\"]] = [dict_trackuri_id[t[0]] for t in artist_tracks[tit] if t[0] in dict_trackuri_id ]    \n",
    "    '''    \n",
    "        \n",
    "        \n",
    "    if tit in dict_ntitle_id.keys(): \n",
    "        # find 10 most similar titles\n",
    "        similar_titles = [tit] + [dict_id_ntitle[m[0]] for m in \n",
    "                      model_ntitle.wv.similar_by_word(dict_ntitle_id[tit], topn=params['TOP_TITLES'], restrict_vocab=None) ]\n",
    "        similar_titles = [s for s in similar_titles if \n",
    "                      (model_ntitle.wv.similarity(dict_ntitle_id[tit],dict_ntitle_id[s])>params['TRESHOLD_TITLES'] and\n",
    "                       sigmas[dict_ntitle_id[s]] < params['THRESHOLD_SIGMAS']\n",
    "                      )]\n",
    "\n",
    "        # take the most common tracks in these TOP_TITLES*1000 tracks \n",
    "        reco = {}\n",
    "        for title in similar_titles:\n",
    "            if title in title_tracks:\n",
    "                for t in title_tracks[title]:\n",
    "                    if t[0] in dict_trackuri_id: \n",
    "                        if dict_trackuri_id[t[0]] not in reco:\n",
    "                            reco[dict_trackuri_id[t[0]]] = 0\n",
    "                        reco[dict_trackuri_id[t[0]]] += t[1]*params['WEIGHT_MULTIPLIER']*model_ntitle.wv.similarity(dict_ntitle_id[tit],dict_ntitle_id[title])\n",
    "\n",
    "        title_recommendations += [r[0] for r in sorted(reco.items(), key=lambda item: item[1] , reverse = True)[:750]]\n",
    "\n",
    "        # if not enough tracks repeats with wider range\n",
    "        if len(title_recommendations)<750:  \n",
    "            similar_titles = [tit] + [dict_id_ntitle[m[0]] for m in model_ntitle.wv.similar_by_word(dict_ntitle_id[tit], topn=10, restrict_vocab=None) ]\n",
    "  \n",
    "            # take the most common tracks in these TOP_TITLES*1000 tracks \n",
    "            reco = {}\n",
    "            for title in similar_titles:\n",
    "                if title in title_tracks:\n",
    "                    for t in title_tracks[title]:\n",
    "                        if t[0] in dict_trackuri_id: \n",
    "                            if dict_trackuri_id[t[0]] not in reco:\n",
    "                                reco[dict_trackuri_id[t[0]]] = 0\n",
    "                            reco[dict_trackuri_id[t[0]]] += t[1]*params['WEIGHT_MULTIPLIER']*model_ntitle.wv.similarity(dict_ntitle_id[tit],dict_ntitle_id[title])\n",
    "\n",
    "            title_recommendations += [r[0] for r in sorted(reco.items(), key=lambda item: item[1] , reverse = True)[:750]]\n",
    "             # if not enough tracks repeats with wider range\n",
    "            if len(title_recommendations)<500:  \n",
    "                similar_titles = [tit] + [dict_id_ntitle[m[0]] for m in model_ntitle.wv.similar_by_word(dict_ntitle_id[tit], topn=20, restrict_vocab=None) ]\n",
    "\n",
    "                # take the most common tracks in these TOP_TITLES*1000 tracks \n",
    "                reco = {}\n",
    "                for title in similar_titles:\n",
    "                    if title in title_tracks:\n",
    "                        for t in title_tracks[title]:\n",
    "                            if t[0] in dict_trackuri_id: \n",
    "                                if dict_trackuri_id[t[0]] not in reco:\n",
    "                                    reco[dict_trackuri_id[t[0]]] = 0\n",
    "                                reco[dict_trackuri_id[t[0]]] += t[1]*params['WEIGHT_MULTIPLIER']*model_ntitle.wv.similarity(dict_ntitle_id[tit],dict_ntitle_id[title])\n",
    "\n",
    "                title_recommendations += [r[0] for r in sorted(reco.items(), key=lambda item: item[1] , reverse = True)[:750]]\n",
    "\n",
    "            if len(title_recommendations)<750: # add popular songs if we have less than 750\n",
    "                title_recommendations = title_recommendations + [str(i) for i in range(1000)]\n",
    "\n",
    "    else:\n",
    "        title_recommendations = title_recommendations + [str(i) for i in range(1000)]\n",
    "    return title_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recomendations_by_track_CENTROID(playlist,model_track,dict_trackuri_id,TOP):\n",
    "    count = 0\n",
    "    average = np.zeros(300)\n",
    "    for t in playlist[\"tracks\"]: \n",
    "        if t[\"track_uri\"] in dict_trackuri_id:    \n",
    "            if dict_trackuri_id[t[\"track_uri\"]] in model_track.wv.vocab:\n",
    "                average = np.add(average, model_track[dict_trackuri_id[t[\"track_uri\"]]])\n",
    "                count += 1\n",
    "    average = average/count\n",
    "    recommendations = [int(m[0]) for m in model_track.wv.similar_by_vector(average, topn=TOP, restrict_vocab=None)]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recsys_model(playlist, title_tracks,recommendations,params):   \n",
    "    count = 0\n",
    "    recommendations[playlist[\"pid\"]]=[]\n",
    "    \n",
    "    # 1 - RECOMMENDATION BY TITLE == ARTIST \n",
    "    '''' ************* RECOMMENDATION BY ARTIST - ARTIST PLAYLIST: *************   '''\n",
    "    if \"name\" in playlist: #check if the playlist has title\n",
    "        rec_artist = playlist_recommend_by_title_artist(playlist)\n",
    "        if(len(rec_artist)>0):\n",
    "            recommendations[playlist[\"pid\"]] = rec_artist\n",
    "                         \n",
    "    \n",
    "    if playlist[\"num_samples\"]==0: # 2 - RECOMMENDATION ONLY BY TITLE:\n",
    "        recommendations[playlist[\"pid\"]] += playlist_recommend_by_title(playlist, title_tracks,params)\n",
    "    elif(playlist[\"num_samples\"]==1):# RECOMMENDATION BY TRACKS  and TITLE \n",
    "        recommendations[playlist[\"pid\"]] = recomendations_by_1_track(playlist,model_track,title_tracks,dict_trackuri_id,2)\n",
    "    elif(playlist[\"num_samples\"]==5):# ECOMMENDATION BY TRACKS  and TITLE\n",
    "        recommendations[playlist[\"pid\"]] = recomendations_by_5_track(playlist,model_track,title_tracks,dict_trackuri_id,params,4,1500,)\n",
    "    elif(playlist[\"num_samples\"]==10):# ECOMMENDATION BY TRACKS  and TITLE\n",
    "        recommendations[playlist[\"pid\"]] = recomendations_by_5_track(playlist,model_track,title_tracks,dict_trackuri_id,params,16,5000)\n",
    "    elif(playlist[\"num_samples\"]==25):# ECOMMENDATION BY TRACKS  and TITLE\n",
    "        recommendations[playlist[\"pid\"]] = recomendations_by_5_track(playlist,model_track,title_tracks,dict_trackuri_id,params,16,5000)\n",
    "    elif(playlist[\"num_samples\"]==100):# ECOMMENDATION BY TRACKS  and TITLE\n",
    "        recommendations[playlist[\"pid\"]] = recomendations_by_5_track(playlist,model_track,title_tracks,dict_trackuri_id,params,16,10000)\n",
    "    \n",
    "    #just in case a small number of recommendations have been created\n",
    "    recommendations[playlist[\"pid\"]] += recommendations[playlist[\"pid\"]] + [str(i) for i in range(500)]\n",
    "        \n",
    "    return recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendations_by_5_track(playlist,model_track,title_tracks,dict_trackuri_id,params,FACTOR_TITLE=2,TOP=510):\n",
    "    seed = playlist['tracks'][0]\n",
    "    id_seed = dict_trackuri_id[seed['track_uri']]\n",
    "    cont = TOP \n",
    "    \n",
    "    rec_by_track= recomendations_by_track_CENTROID(playlist,model_track,dict_trackuri_id,TOP)\n",
    "    \n",
    "    r = {}\n",
    "    for item in rec_by_track:\n",
    "        r[str(item)]= cont\n",
    "        cont-=1\n",
    "    if \"name\" in playlist:\n",
    "        rec_by_title = playlist_recommend_by_title(playlist, title_tracks,params)[:TOP]\n",
    "        cont = TOP     \n",
    "        for item in rec_by_title:\n",
    "            if(item in r):\n",
    "                r[item] = r[item] + cont/FACTOR_TITLE\n",
    "            else:\n",
    "                r[item]= cont/FACTOR_TITLE\n",
    "            cont-=1\n",
    "\n",
    "    sorted_list=sorted(r.items(), key=lambda x: x[1],reverse=True)\n",
    "    recommendations = [item[0] for item in sorted_list]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recomendations_by_1_track(playlist,model_track,title_tracks,dict_trackuri_id,FACTOR_TITLE =2):\n",
    "    df2 = pd.read_csv('../../MPD/src//track_info2.csv',index_col='Unnamed: 0')\n",
    "    TOP = 5000\n",
    "    seed = playlist['tracks'][0]\n",
    "    id_seed = dict_trackuri_id[seed['track_uri']]\n",
    "    cont = TOP \n",
    "    if(int(id_seed)<590000):\n",
    "        rec_by_track = model_track.wv.similar_by_vector(id_seed, topn=TOP, restrict_vocab=None)\n",
    "    else:\n",
    "        rec_by_track=[]\n",
    "    rec_by_title = playlist_recommend_by_title(playlist, title_tracks)[:TOP]\n",
    "\n",
    "    r = {}\n",
    "    for item in rec_by_track:\n",
    "        r[item[0]]= cont\n",
    "        cont-=1\n",
    "    cont = TOP     \n",
    "    for item in rec_by_title:\n",
    "        if(item in r):\n",
    "            r[item] = r[item] + cont/FACTOR_TITLE\n",
    "        else:\n",
    "            r[item]= cont/FACTOR_TITLE\n",
    "        cont-=1\n",
    "\n",
    "    \n",
    "    # add the 20 most populars songs for each of the similar artist to the seed\n",
    "    if(int(id_seed)>=0):\n",
    "        seed_artsist_id = dict_artisturi_id[playlist['tracks'][0]['artist_uri']]\n",
    "        num_per_artist = 40\n",
    "        if(int(seed_artsist_id)<194169): #artists with id higher than this are not considered since embedding are not computed\n",
    "            # add top song of the seed artist:\n",
    "            songs2add = df2[df2['artist_uri']==playlist['tracks'][0]['artist_uri']].sort_values(by='num_times',ascending=False)[:10].index\n",
    "            songs2add = sorted([ int(dict_trackuri_id[s]) for s in sorted(songs2add)])[:num_per_artist]\n",
    "            #add top songs of the similiar artist\n",
    "            cont = num_per_artist     \n",
    "            for item2 in songs2add:\n",
    "                if(str(item2) in r):\n",
    "                    r[str(item2)] = r[str(item2)] + cont*100\n",
    "                else:\n",
    "                    r[str(item2)]= cont*100\n",
    "                cont = cont-1\n",
    "                \n",
    "            most_similar = model_artist.wv.most_similar(seed_artsist_id,topn=num_per_artist)\n",
    "            for id_a in most_similar:\n",
    "                songs2add = df2[df2['artist_uri']==dict_id_trackuri[id_a[0]]].sort_values(by='num_times',ascending=False)[:10].index\n",
    "                songs2add = sorted([ int(dict_trackuri_id[s]) for s in sorted(songs2add)])[:10]\n",
    "                #add top songs of the similiar artist\n",
    "                cont = num_per_artist     \n",
    "                for item2 in songs2add:\n",
    "                    if(str(item2) in r):\n",
    "                        r[str(item2)] = r[str(item2)] + cont*100\n",
    "                    else:\n",
    "                        r[str(item2)]= cont*100\n",
    "                    cont = cont-1\n",
    "    \n",
    "    # rescore items according to the popularity\n",
    "    for item in r:\n",
    "        r[item] =r[item]* np.log(1+df2.loc[dict_id_trackuri[item]].num_times)\n",
    "        \n",
    "    sorted_list=sorted(r.items(), key=lambda x: x[1],reverse=True)\n",
    "    recommendations = [item[0] for item in sorted_list]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "params = {}\n",
    "params['TOP'] = 800             \n",
    "params['TOP_TITLES'] = 10\n",
    "params['TRESHOLD_TITLES'] = 0.6\n",
    "params['THRESHOLD_SIGMAS'] = 0.1\n",
    "params['WEIGHT_MULTIPLIER'] = 2\n",
    "\n",
    "def create_submission(recsys_model,name):\n",
    "    \n",
    "    process_challenge_set(recsys_model,name,dict_trackuri_id,dict_id_trackuri,title_tracks,params) \n",
    "    !python \"utils_spotify/verify_submission.py\" \"utils_spotify/challenge_set.json\" \"submission.csv\"\n",
    "    with open('submission.csv', 'rb') as f_in:\n",
    "        with gzip.open('submission.csv.gz', 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "            \n",
    "name= \"submission\"\n",
    "create_submission(recsys_model,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
