{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## filtered csv common_titles\n",
    "\n",
    "it creates 2 dictionaries:\n",
    "* normalized titles and the number of appearences\n",
    "* normalized titles and its 1000 most common tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os## filtered csv common_titles\n",
    "import datetime\n",
    "import csv\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm_notebook\n",
    "from whoosh.analysis import CharsetFilter, StemmingAnalyzer\n",
    "from whoosh import fields\n",
    "from whoosh.support.charset import accent_map\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from whoosh.analysis import CharsetFilter, StemmingAnalyzer\n",
    "from whoosh import fields\n",
    "from whoosh.support.charset import accent_map\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import ascii_letters\n",
    "from utils import normalize_name\n",
    "\n",
    "\n",
    "quick = False\n",
    "max_files_for_quick_processing = 1\n",
    "\n",
    "mpd_path = '../../MPD/data/' #DEFINE YOUR PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making dictionary of titles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc191702e55441bbc964e336bba84fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "filling dictionary of titles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb91d49db1944ccda6489a1047c964c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuting to best 1000 tracks...\n",
      "dictionaries successfully saved\n",
      "number of playlists 1000000\n",
      "number of unique normalized titles 15875\n"
     ]
    }
   ],
   "source": [
    "total_playlists = 0\n",
    "title_histogram = collections.Counter()\n",
    "dict_sorted_titles = dict()\n",
    "\n",
    "def process_mpd(path):\n",
    "    print(\"making dictionary of titles...\")\n",
    "    create_common_titles(path)\n",
    "    reorder()\n",
    "    print(\"filling dictionary of titles...\")\n",
    "    fill_common_titles(path)\n",
    "    print(\"cuting to best 1000 tracks...\")\n",
    "    cut_1000()   \n",
    "    np.save('dictionaries/ntitles_1000tracks_final', dict_sorted_titles) \n",
    "    print(\"dictionaries successfully saved\")\n",
    "    show_summary()\n",
    "\n",
    "def create_common_titles(path):\n",
    "    global total_playlists\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in tqdm_notebook(sorted(filenames)):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "                total_playlists+=1\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "                \n",
    "def reorder():\n",
    "    global dict_sorted_titles\n",
    "    if not os.path.exists(\"dictionaries\"):\n",
    "        os.makedirs(\"dictionaries\")\n",
    "    dict_sorted_titles = collections.OrderedDict(title_histogram.most_common())\n",
    "    np.save('dictionaries/dict_ntitles_final', dict_sorted_titles)\n",
    "    for word in dict_sorted_titles:\n",
    "        dict_sorted_titles[word]=collections.Counter()\n",
    "    \n",
    "        \n",
    "        \n",
    "def fill_common_titles(path):\n",
    "    global dict_sorted_titles\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in tqdm_notebook(sorted(filenames)):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                title = normalize_name(playlist[\"name\"])\n",
    "                if title in dict_sorted_titles.keys():\n",
    "                    for track in playlist[\"tracks\"]:\n",
    "                        dict_sorted_titles[title][track[\"track_uri\"]] += 1    \n",
    "                else: print(title)\n",
    "                             \n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "                \n",
    "def cut_1000():\n",
    "    \n",
    "     # cut to 1000 best tracks \n",
    "    for title in dict_sorted_titles:\n",
    "        if type(dict_sorted_titles[title])!=collections.Counter:\n",
    "            print(title,type(dict_sorted_titles[title]))\n",
    "        else:\n",
    "            dict_sorted_titles[title] = dict_sorted_titles[title].most_common(1000)\n",
    "            #genre_tracks[ti] = [l[0] for l in genre_tracks[ti]]\n",
    "            #if len(genre_tracks[ti])<600:\n",
    "            #    not_enough+=1 \n",
    "    \n",
    "\n",
    "def show_summary():\n",
    "    print (\"number of playlists\", total_playlists)\n",
    "    print (\"number of unique normalized titles\", len(dict_sorted_titles))\n",
    "        \n",
    "\n",
    "\n",
    "def process_playlist(playlist):\n",
    "    nname = normalize_name(playlist['name'])\n",
    "    title_histogram[nname] += 1\n",
    "\n",
    "\n",
    "process_mpd(mpd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making dictionary of artists...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54dc714a31b472faee8977b9a4045e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('drake', 847163), ('kanye west', 413297), ('kendrick lamar', 353624), ('rihanna', 339570), ('weeknd', 316608), ('eminem', 294667), ('ed sheeran', 272116), ('futur', 250854), ('justin bieber', 243119), ('cole', 241572), ('beyonce', 230857), ('chainsmok', 223509), ('chri brown', 212772), ('calvin harri', 203047), ('twenti on pilot', 198905), ('lil uzi vert', 197855), ('post malon', 195907), ('jai', 193999), ('eazi', 193708), ('big sean', 192478), ('maroon', 187033), ('migo', 184458), ('coldplai', 182350), ('lil wayne', 176657), ('rae sremmurd', 168351), ('imagin dragon', 167940), ('bruno mar', 162464), ('childish gambino', 159872), ('nicki minaj', 152655), ('luke bryan', 146260), ('wiz khalifa', 145689), ('fall out boi', 142767), ('ariana grand', 142115), ('usher', 141505), ('logic', 140449), ('john mayer', 139947), ('travi scot', 139928), ('on direct', 139554), ('chanc rapper', 137960), ('dj khale', 137523), ('panic disco', 136328), ('florida georgia line', 135666), ('red hot chili pepper', 131091), ('beatl', 129902), ('kati perri', 128866), ('fetti wap', 128197), ('khalid', 126733), ('milei cyru', 126658), ('major lazer', 126353), ('jason derulo', 124734), ('zac brown band', 123824), ('ap rocki', 123178), ('frank ocean', 122188), ('justin timberlak', 121270), ('flo rida', 120288), ('kodak black', 119351), ('lana del rei', 118953), ('queen', 117753), ('young thug', 117262), ('kid cudi', 116743), ('michael jackson', 116439), ('lumin', 112920), ('david guetta', 110201), ('adel', 109301), ('shawn mend', 108792), ('sam hunt', 106917), ('onerepubl', 106047), ('taylor swift', 105366), ('gucci mane', 103416), ('21 savag', 103076), ('michael buble', 102627), ('jeremih', 102514), ('mumford son', 102303), ('halsei', 101850), ('thoma rhet', 101531), ('flume', 101422), ('chainz', 100804), ('pitbul', 100698), ('sam smith', 100334), ('kenni chesnei', 99625), ('blink 182', 98241), ('kygo', 97625), ('selena gomez', 96827), ('kevin gate', 96389), ('tim mcgraw', 96253), ('roll stone', 95542), ('bryson tiller', 94963), ('sia', 94961), ('trei songz', 94552), ('rus', 94369), ('jack johnson', 91578), ('blackbear', 91295), ('avici', 91265), ('blake shelton', 90945), ('jason aldean', 90543), ('demi lovato', 89877), ('lord', 88886), ('zed', 88513), ('britnei spear', 88046), ('arctic monkei', 87981)]\n",
      "filling dictionary of artists...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c612e502c842088991f0534b60e805"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_playlists = 0\n",
    "artist_histogram = collections.Counter()\n",
    "dict_sorted_artists = dict()\n",
    "\n",
    "quick = False\n",
    "max_files_for_quick_processing = 1\n",
    "\n",
    "def process_mpd(path):\n",
    "    print(\"making dictionary of artists...\")\n",
    "    create_common_artists(path)\n",
    "    reorder()\n",
    "    print(\"filling dictionary of artists...\")\n",
    "    fill_common_artists(path)\n",
    "    print(\"cuting to best 1000 tracks...\")\n",
    "    cut_1000()   \n",
    "    np.save('dictionaries/nartists_1000tracks_final', dict_sorted_artists) \n",
    "    print(\"dictionaries successfully saved\")\n",
    "    show_summary()\n",
    "\n",
    "def create_common_artists(path):\n",
    "    global total_playlists\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in tqdm_notebook(sorted(filenames)):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "                total_playlists+=1\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "                \n",
    "def reorder():\n",
    "    global dict_sorted_artists\n",
    "    dict_sorted_artists = collections.OrderedDict(artist_histogram.most_common())\n",
    "    np.save('dictionaries/dict_nartists_final', dict_sorted_artists)\n",
    "    for word in dict_sorted_artists:\n",
    "        dict_sorted_artists[word]=collections.Counter()\n",
    "    \n",
    "    print(artist_histogram.most_common(100))\n",
    "    \n",
    "        \n",
    "        \n",
    "def fill_common_artists(path):\n",
    "    global dict_sorted_artists\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in tqdm_notebook(sorted(filenames)):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                for track in playlist[\"tracks\"]:\n",
    "                    artist = normalize_name(track[\"artist_name\"])\n",
    "                    if artist in dict_sorted_artists.keys():\n",
    "                        dict_sorted_artists[artist][track[\"track_uri\"]] += 1    \n",
    "                    else: print(artist)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "                \n",
    "def cut_1000():\n",
    "    \n",
    "     # cut to 1000 best tracks \n",
    "    for artist in dict_sorted_artist:\n",
    "        if type(dict_sorted_artists[artist])!=Counter:\n",
    "            print(artist,type(dict_sorted_artists[artist]))\n",
    "        else:\n",
    "            dict_sorted_artists[artist] = dict_sorted_artists[artist].most_common(1000)\n",
    "            #genre_tracks[ti] = [l[0] for l in genre_tracks[ti]]\n",
    "            #if len(genre_tracks[ti])<600:\n",
    "            #    not_enough+=1 \n",
    "    \n",
    "\n",
    "def show_summary():\n",
    "    print (\"number of unique normalized artists\", len(dict_sorted_artists))\n",
    "        \n",
    "\n",
    "\n",
    "def process_playlist(playlist):\n",
    "    for track in playlist[\"tracks\"]:\n",
    "        nname = normalize_name(track['artist_name'])\n",
    "        artist_histogram[nname] += 1\n",
    "\n",
    "\n",
    "process_mpd(mpd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
