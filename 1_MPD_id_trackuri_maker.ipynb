{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV file maker track uri - numeric ID\n",
    "Makes a csv that assigns each track_uri a numeric ID <br>\n",
    "The higher the ID is, the most popular the track is <br>\n",
    "Also makes the following dictionaries:\n",
    "* Trackuri - ID\n",
    "* Trackuri - title\n",
    "* ID - title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg  as la\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook\n",
    "import collections \n",
    "from whoosh.analysis import CharsetFilter, StemmingAnalyzer\n",
    "from whoosh import fields\n",
    "from whoosh.support.charset import accent_map\n",
    "from utils import normalize_name\n",
    "\n",
    "mpd_path = '../../MPD/data/' #DEFINE YOUR PATH\n",
    "\n",
    "\n",
    "quick = False\n",
    "max_files_for_quick_processing = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d7cccc3031442d9abeaa4e27a3ab01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of tracks 66346428\n",
      "number of unique tracks 2262292\n",
      "number tracks appearing > 4 times: 599341 that is 26.49%\n",
      "number of playlists 1000000\n"
     ]
    }
   ],
   "source": [
    "total_tracks = 0\n",
    "track_histogram = collections.Counter()\n",
    "num = 4\n",
    "dict_sorted_trackuri_id = dict()\n",
    "dict_trackuri_title = dict()\n",
    "dict_playlistpid_title = dict()\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in tqdm_notebook(sorted(filenames)):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "\n",
    "    reorder()\n",
    "    write_files()\n",
    "\n",
    "    \n",
    "def write_files():\n",
    "    if not os.path.exists(\"dictionaries\"):\n",
    "        os.makedirs(\"dictionaries\")\n",
    "    \n",
    "    \n",
    "    with open('dictionaries/dict_sorted_trackuri_id.csv', 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"id\",\"track_uri\"])\n",
    "        for trackuri in dict_sorted_trackuri_id:\n",
    "            spamwriter.writerow([trackuri,dict_sorted_trackuri_id[trackuri]])\n",
    "    \n",
    "    with open('dictionaries/dict_trackuri_title.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"track_uri\",\"title\"])\n",
    "        for trackuri in dict_trackuri_title:\n",
    "            spamwriter.writerow([trackuri,dict_trackuri_title[trackuri]])\n",
    "            \n",
    "    with open('dictionaries/dict_id_title.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"track_uri\",\"title\"])\n",
    "        for trackuri in dict_trackuri_title:\n",
    "            spamwriter.writerow([dict_sorted_trackuri_id[trackuri],dict_trackuri_title[trackuri]])\n",
    "            \n",
    "    with open('dictionaries/dict_playlistpid_title.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"playlist_pid\",\"title\"])\n",
    "        for pid in dict_playlistpid_title:\n",
    "            spamwriter.writerow([pid,dict_playlistpid_title[pid]])\n",
    "            \n",
    "        \n",
    "# reorders by popularity, selects the ones appeareing more than 4 times and makes dictionary\n",
    "def reorder():\n",
    "    # tracks sorted by popularity\n",
    "    dict_sorted_occurences = collections.OrderedDict(track_histogram.most_common())\n",
    "    # assign each track an id, track: new_id, where the lowest the new_id is, the most common is the track\n",
    "    for word in dict_sorted_occurences:\n",
    "        dict_sorted_trackuri_id[word] = len(dict_sorted_trackuri_id)\n",
    "    \n",
    "        \n",
    "    t1 = len(list(filter(lambda y: y[1]>4, track_histogram.items())))\n",
    "    print(\"number of tracks\", total_tracks)\n",
    "    print(\"number of unique tracks\", len(track_histogram))\n",
    "    print(\"number tracks appearing > \"+str(num)+\" times: \"+ str(t1) +\n",
    "          \" that is \"+ str(round(t1/len(track_histogram)*100,2))+\"%\" )\n",
    "    print(\"number of playlists\", len(dict_playlistpid_title))\n",
    "\n",
    "# fills track_histogram\n",
    "def process_playlist(playlist):\n",
    "    global total_tracks\n",
    "    \n",
    "    if playlist['pid'] not in dict_playlistpid_title:\n",
    "        dict_playlistpid_title[playlist['pid']] = playlist['name']\n",
    "    \n",
    "    for track in playlist['tracks']:\n",
    "        total_tracks += 1\n",
    "        track_histogram[track['track_uri']] += 1\n",
    "        if track['track_uri'] not in dict_trackuri_title:\n",
    "            dict_trackuri_title[track['track_uri']]= track[\"track_name\"]\n",
    "            \n",
    "        \n",
    "        \n",
    "process_mpd(mpd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723bc0b34be543229bea1ac9223cd4ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of unique artists 295860\n",
      "number of unique normalized titles: 15875\n"
     ]
    }
   ],
   "source": [
    "total_artists = 0\n",
    "artist_histogram = collections.Counter()\n",
    "dict_artisturi_id = dict()\n",
    "dict_artisturi_artist = dict()\n",
    "\n",
    "total_normalized_titles = 0\n",
    "ntitles_histogram = collections.Counter()\n",
    "dict_ntitle_id = dict()\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in tqdm_notebook(sorted(filenames)):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "\n",
    "    reorder()\n",
    "    write_files()\n",
    "\n",
    "def write_files():\n",
    "    if not os.path.exists(\"dictionaries\"):\n",
    "        os.makedirs(\"dictionaries\")\n",
    "    with open('dictionaries/dict_artisturi_id.csv', 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"artist_uri\",\"id\"])\n",
    "        for artisturi in dict_artisturi_id:\n",
    "            spamwriter.writerow([artisturi,dict_artisturi_id[artisturi]])\n",
    "    \n",
    "    with open('dictionaries/dict_artisturi_artist.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"artist_uri\",\"artist\"])\n",
    "        for uri in dict_artisturi_artist:\n",
    "            spamwriter.writerow([uri,dict_artisturi_artist[uri]])\n",
    "        \n",
    "            \n",
    "    with open('dictionaries/dict_id_ntitle_final.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"id\",\"normalized_title\"])\n",
    "        for title in dict_ntitle_id.keys():\n",
    "            spamwriter.writerow([dict_ntitle_id[title],title] )\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "# reorders by popularity, selects the ones appeareing more than 4 times and makes dictionary\n",
    "def reorder():\n",
    "    # tracks sorted by popularity\n",
    "    dict_sorted_occurences_artist = collections.OrderedDict(artist_histogram.most_common())\n",
    "    dict_sorted_occurences_ntitle = collections.OrderedDict(ntitles_histogram.most_common())\n",
    "    \n",
    "    # assign each track an id, track: new_id, where the lowest the new_id is, the most common is the artist/album\n",
    "    for word in dict_sorted_occurences_artist:\n",
    "        dict_artisturi_id[word] = len(dict_artisturi_id)\n",
    "    for word in dict_sorted_occurences_ntitle:\n",
    "        dict_ntitle_id[word] = len(dict_ntitle_id)\n",
    "    \n",
    "    print(\"number of unique artists\", len(artist_histogram))\n",
    "    print(\"number of unique normalized titles: \"+str(len(dict_ntitle_id)))\n",
    "    ar = len(list(filter(lambda y: y[1]>4, artist_histogram.items())))\n",
    "    \n",
    "    \n",
    "# fills track_histogram\n",
    "def process_playlist(playlist):\n",
    "    ntitles_histogram[normalize_name(playlist[\"name\"])] += 1\n",
    "   \n",
    "    for track in playlist['tracks']:\n",
    "        artist_histogram[track['artist_uri']] += 1\n",
    "        \n",
    "        \n",
    "    # creating the dictionaries with original artist and album names \n",
    "    if track['artist_uri'] not in dict_artisturi_artist:\n",
    "        dict_artisturi_artist[track['artist_uri']]= track[\"artist_name\"]   \n",
    "    \n",
    "        \n",
    "process_mpd(mpd_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
