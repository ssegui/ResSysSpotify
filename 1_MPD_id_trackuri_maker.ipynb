{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV file maker track uri - numeric ID\n",
    "Makes a csv that assigns each track_uri a numeric ID <br>\n",
    "The higher the ID is, the most popular the track is <br>\n",
    "Also makes the following dictionaries:\n",
    "* Trackuri - ID\n",
    "* Trackuri - title\n",
    "* ID - title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   usage:\n",
    "\n",
    "        python 1_MPD_id_trackuri_maker.py path-to-mpd-data/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg  as la\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter, OrderedDict\n",
    "from whoosh.analysis import CharsetFilter, StemmingAnalyzer\n",
    "from whoosh import fields\n",
    "from whoosh.support.charset import accent_map\n",
    "\n",
    "def normalize_name(name):\n",
    "    stem = True\n",
    "  \n",
    "    letters = list(name)\n",
    "    \n",
    "    # if format w o r k o u t / w.o.r.k.o.u.t/ w*o*r*k*o*u*t join togother\n",
    "    if len(letters)>4:\n",
    "        if len(set([letters[i] for i in range(0,len(letters),2)]))==1:\n",
    "            name = \"\".join([letters[i] for i in range(1,len(letters),2)])\n",
    "        elif len(set([letters[i] for i in range(1,len(letters),2)]))==1:\n",
    "            name = \"\".join([letters[i] for i in range(0,len(letters),2)])\n",
    "             \n",
    "    # if there is and & not surrounded by spaces, leave alone (example 'r&b)\n",
    "    if \"&\" in letters:\n",
    "        position = letters.index(\"&\")\n",
    "        if position>0 and position<len(letters)-1:\n",
    "            if letters[position-1]!=' ' and letters[position+1]!=' ':\n",
    "                stem  = False\n",
    "    \n",
    "      \n",
    "    # if there is a k surrounded by numbers turn to 0\n",
    "    if \"k\" in letters and '2' in letters:\n",
    "        positions = [x for x in range(len(letters)) if letters[x]=='k']\n",
    "        for pos in positions:\n",
    "             if pos>0 and pos<len(letters)-1:\n",
    "                if letters[pos-1]=='2':\n",
    "                    letters[pos]='0'\n",
    "                    name = \"\".join(letters)\n",
    "           \n",
    "    # proceed to stem   \n",
    "    if stem: \n",
    "        my_analyzer = StemmingAnalyzer() | CharsetFilter(accent_map)\n",
    "        tokens = my_analyzer(name)\n",
    "        words = [token.text for token in tokens]\n",
    "        \n",
    "        # if the reuslt is empyt, leave alone, if not, return as a list\n",
    "        if len(words)!=0:\n",
    "            result=\"\"\n",
    "            for el in words:\n",
    "                result +=el+\" \"\n",
    "            letters = list(result)[:-1]\n",
    "    # softer stem\n",
    "    else:\n",
    "        name = name.lower()\n",
    "        name = re.sub(r\"[.,\\/#!$%\\^\\*;:{}=\\_`~()@]\", ' ', name)\n",
    "        name = re.sub(r'\\s+', ' ', name).strip()\n",
    "        letters = list(name)\n",
    "        \n",
    "            \n",
    "            \n",
    "    # if last n characters are equal leave only 1 \n",
    "    last = letters[-1]\n",
    "    if last in ascii_letters and len(letters)>1:\n",
    "        while(letters[-2]==last):\n",
    "            letters.pop(-2)\n",
    "            if len(letters)==1: break\n",
    "    \n",
    "    \n",
    "    return ''.join(letters)\n",
    "\n",
    "total_tracks = 0\n",
    "track_histogram = collections.Counter()\n",
    "num = 4\n",
    "dict_sorted_trackuri_id = dict()\n",
    "dict_trackuri_title = dict()\n",
    "dict_playlistpid_title = dict()\n",
    "\n",
    "\n",
    "quick = False\n",
    "max_files_for_quick_processing = 1\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in tqdm_notebook(sorted(filenames)):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "\n",
    "    reorder()\n",
    "    write_files()\n",
    "\n",
    "    \n",
    "def write_files():\n",
    "    if not os.path.exists(\"dictionaries\"):\n",
    "        os.makedirs(\"dictionaries\")\n",
    "    \n",
    "    \n",
    "    with open('dictionaries/dict_sorted_trackuri_id.csv', 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"id\",\"track_uri\"])\n",
    "        for trackuri in dict_sorted_trackuri_id:\n",
    "            spamwriter.writerow([trackuri,dict_sorted_trackuri_id[trackuri]])\n",
    "    \n",
    "    with open('dictionaries/dict_trackuri_title.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"track_uri\",\"title\"])\n",
    "        for trackuri in dict_trackuri_title:\n",
    "            spamwriter.writerow([trackuri,dict_trackuri_title[trackuri]])\n",
    "            \n",
    "    with open('dictionaries/dict_id_title.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"track_uri\",\"title\"])\n",
    "        for trackuri in dict_trackuri_title:\n",
    "            spamwriter.writerow([dict_sorted_trackuri_id[trackuri],dict_trackuri_title[trackuri]])\n",
    "            \n",
    "    with open('dictionaries/dict_playlistpid_title.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"playlist_pid\",\"title\"])\n",
    "        for pid in dict_playlistpid_title:\n",
    "            spamwriter.writerow([pid,dict_playlistpid_title[pid]])\n",
    "            \n",
    "        \n",
    "# reorders by popularity, selects the ones appeareing more than 4 times and makes dictionary\n",
    "def reorder():\n",
    "    # tracks sorted by popularity\n",
    "    dict_sorted_occurences = OrderedDict(track_histogram.most_common())\n",
    "    # assign each track an id, track: new_id, where the lowest the new_id is, the most common is the track\n",
    "    for word in dict_sorted_occurences:\n",
    "        dict_sorted_trackuri_id[word] = len(dict_sorted_trackuri_id)\n",
    "    \n",
    "        \n",
    "    t1 = len(list(filter(lambda y: y[1]>4, track_histogram.items())))\n",
    "    print(\"number of tracks\", total_tracks)\n",
    "    print(\"number of unique tracks\", len(track_histogram))\n",
    "    print(\"number tracks appearing > \"+str(num)+\" times: \"+ str(t1) +\n",
    "          \" that is \"+ str(round(t1/len(track_histogram)*100,2))+\"%\" )\n",
    "    print(\"number of playlists\", len(dict_playlistpid_title))\n",
    "\n",
    "# fills track_histogram\n",
    "def process_playlist(playlist):\n",
    "    global total_tracks\n",
    "    \n",
    "    if playlist['pid'] not in dict_playlistpid_title:\n",
    "        dict_playlistpid_title[playlist['pid']] = playlist['name']\n",
    "    \n",
    "    for track in playlist['tracks']:\n",
    "        total_tracks += 1\n",
    "        track_histogram[track['track_uri']] += 1\n",
    "        if track['track_uri'] not in dict_trackuri_title:\n",
    "            dict_trackuri_title[track['track_uri']]= track[\"track_name\"]\n",
    "            \n",
    "        \n",
    "        \n",
    "process_mpd('../../MPD/data/')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
